// This file is for use with Gemini Code Assist in VS Code/Codespaces
// To use, install Gemini Code Assist extension, then use the comment prompt below

/**
 * Terraform configuration for GCP workstation with GPUs
 * Deploys n2d-standard-32 with 2x T4 GPUs for project cherry-ai-project
 * 
 * To generate with Gemini Code Assist, use:
 * /generate terraform to deploy n2d-standard-32 with T4 GPUs for project cherry-ai-project
 */

// The template below will be generated by Gemini Code Assist when prompted
// This is a template for what it should look like:

/**
 * GCP Workstation Terraform Configuration
 * Deploys n2d-standard-32 with 2x NVIDIA T4 GPUs
 */

// Terraform file to be saved as main.tf
const terraformConfig = `# Terraform configuration for GCP Cloud Workstation with GPUs
# Deploys n2d-standard-32 with 2x NVIDIA T4 GPUs for project cherry-ai-project

terraform {
  required_providers {
    google = {
      source  = "hashicorp/google"
      version = "~> 4.0"
    }
  }
}

# Configure the Google Cloud provider
provider "google" {
  project = "cherry-ai-project"
  region  = "us-west4"
}

# Variables
variable "project_id" {
  description = "The ID of the project"
  type        = string
  default     = "cherry-ai-project"
}

variable "region" {
  description = "The region to deploy to"
  type        = string
  default     = "us-west4"
}

variable "zone" {
  description = "The zone to deploy to"
  type        = string
  default     = "us-west4-a"
}

variable "cluster_name" {
  description = "Name of the workstation cluster"
  type        = string
  default     = "ai-development"
}

variable "workstation_config_name" {
  description = "Name of the workstation configuration"
  type        = string
  default     = "ai-dev-config"
}

variable "machine_type" {
  description = "Machine type for the workstation"
  type        = string
  default     = "n2d-standard-32"
}

variable "gpu_type" {
  description = "Type of GPU"
  type        = string
  default     = "nvidia-tesla-t4"
}

variable "gpu_count" {
  description = "Number of GPUs"
  type        = number
  default     = 2
}

# Random ID for unique naming
resource "random_id" "workstation_suffix" {
  byte_length = 4
}

# Enable required APIs
resource "google_project_service" "workstations_api" {
  project = var.project_id
  service = "workstations.googleapis.com"

  disable_dependent_services = false
  disable_on_destroy         = false
}

resource "google_project_service" "compute_api" {
  project = var.project_id
  service = "compute.googleapis.com"

  disable_dependent_services = false
  disable_on_destroy         = false
}

# Create a Cloud Workstation Cluster
resource "google_workstations_workstation_cluster" "ai_cluster" {
  provider               = google
  project                = var.project_id
  region                 = var.region
  workstation_cluster_id = var.cluster_name
  
  network {
    network = "default"
  }
  
  private_cluster_config {
    enable_private_endpoint = false
  }
  
  depends_on = [
    google_project_service.workstations_api,
    google_project_service.compute_api
  ]
}

# Create a Workstation Configuration
resource "google_workstations_workstation_config" "ai_config" {
  provider               = google
  project                = var.project_id
  region                 = var.region
  workstation_cluster_id = google_workstations_workstation_cluster.ai_cluster.workstation_cluster_id
  workstation_config_id  = var.workstation_config_name
  
  host {
    gce_instance {
      machine_type = var.machine_type
      
      accelerators {
        type  = var.gpu_type
        count = var.gpu_count
      }
      
      boot_disk_size_gb = 100
      
      shielded_instance_config {
        enable_secure_boot = true
      }
    }
  }
  
  persistent_directories {
    mount_path = "/home"
    gce_pd {
      size_gb        = 200
      reclaim_policy = "DELETE"
    }
  }
  
  container {
    image = "us-docker.pkg.dev/cloud-workstations-images/predefined/code-oss:latest"
    
    env {
      name  = "GPU_ENABLED"
      value = "true"
    }
    
    working_directory = "/home"
    
    command = [
      "/opt/code-oss/code-oss",
      "--host", "0.0.0.0",
      "--port", "8080",
    ]
  }
}

# Create a Workstation
resource "google_workstations_workstation" "ai_workstation" {
  provider               = google
  project                = var.project_id
  region                 = var.region
  workstation_cluster_id = google_workstations_workstation_cluster.ai_cluster.workstation_cluster_id
  workstation_config_id  = google_workstations_workstation_config.ai_config.workstation_config_id
  workstation_id         = "ai-workstation-\${random_id.workstation_suffix.hex}"
}

# Outputs
output "cluster_name" {
  value = google_workstations_workstation_cluster.ai_cluster.workstation_cluster_id
}

output "config_name" {
  value = google_workstations_workstation_config.ai_config.workstation_config_id
}

output "workstation_name" {
  value = google_workstations_workstation.ai_workstation.workstation_id
}

output "machine_type" {
  value = var.machine_type
}

output "gpu_type" {
  value = var.gpu_type
}

output "gpu_count" {
  value = var.gpu_count
}

output "console_url" {
  value = "https://console.cloud.google.com/workstations/clusters/\${var.cluster_name}/configs?project=\${var.project_id}"
}
`;

// Terraform file to be saved as variables.tf
const terraformVariables = `# variables.tf - variables for Cloud Workstation deployment

variable "project_id" {
  description = "The ID of the project"
  type        = string
  default     = "cherry-ai-project"
}

variable "region" {
  description = "The region to deploy to"
  type        = string
  default     = "us-west4"
}

variable "zone" {
  description = "The zone to deploy to"
  type        = string
  default     = "us-west4-a"
}

variable "cluster_name" {
  description = "Name of the workstation cluster"
  type        = string
  default     = "ai-development"
}

variable "workstation_config_name" {
  description = "Name of the workstation configuration"
  type        = string
  default     = "ai-dev-config"
}

variable "machine_type" {
  description = "Machine type for the workstation"
  type        = string
  default     = "n2d-standard-32"
}

variable "gpu_type" {
  description = "Type of GPU"
  type        = string
  default     = "nvidia-tesla-t4"
}

variable "gpu_count" {
  description = "Number of GPUs"
  type        = number
  default     = 2
}
`;

// Terraform file to be saved as outputs.tf
const terraformOutputs = `# outputs.tf - outputs for Cloud Workstation deployment

output "cluster_name" {
  value       = google_workstations_workstation_cluster.ai_cluster.workstation_cluster_id
  description = "The name of the created workstation cluster"
}

output "config_name" {
  value       = google_workstations_workstation_config.ai_config.workstation_config_id
  description = "The name of the created workstation configuration"
}

output "workstation_name" {
  value       = google_workstations_workstation.ai_workstation.workstation_id
  description = "The name of the created workstation"
}

output "machine_type" {
  value       = var.machine_type
  description = "The machine type used for the workstation"
}

output "gpu_type" {
  value       = var.gpu_type
  description = "The GPU type used for the workstation"
}

output "gpu_count" {
  value       = var.gpu_count
  description = "The number of GPUs used for the workstation"
}

output "console_url" {
  value       = "https://console.cloud.google.com/workstations/clusters/\${var.cluster_name}/configs?project=\${var.project_id}"
  description = "URL to access the workstation in the GCP console"
}
`;

// Terraform file to be saved as terraform.tfvars
const terraformTFVars = `# terraform.tfvars - Variable values for Cloud Workstation deployment

project_id              = "cherry-ai-project"
region                  = "us-west4"
zone                    = "us-west4-a"
cluster_name            = "ai-development"
workstation_config_name = "ai-dev-config"
machine_type            = "n2d-standard-32"
gpu_type                = "nvidia-tesla-t4"
gpu_count               = 2
`;

// Shell script to be saved as deploy.sh
const deployScript = `#!/bin/bash
# deploy.sh - Script to deploy GCP Cloud Workstation with Terraform

set -e

echo "===== Deploying GCP Cloud Workstation with Terraform ====="
echo "Project: cherry-ai-project"
echo "Machine Type: n2d-standard-32"
echo "GPUs: 2x NVIDIA T4"
echo

# Initialize Terraform
echo "Initializing Terraform..."
terraform init

# Validate Terraform configuration
echo "Validating Terraform configuration..."
terraform validate

# Plan Terraform deployment
echo "Planning Terraform deployment..."
terraform plan -out=workstation.tfplan

# Prompt for deployment confirmation
read -p "Deploy workstation? (y/n): " DEPLOY_CONFIRM
if [[ "$DEPLOY_CONFIRM" == "y" ]]; then
  echo "Deploying workstation..."
  terraform apply workstation.tfplan
  
  echo "===== Deployment Complete ====="
  echo "Workstation has been deployed with n2d-standard-32 and 2x NVIDIA T4 GPUs."
  echo "Check the GCP Console for details."
else
  echo "Deployment cancelled."
fi
`;

// Function to set up the Terraform project structure
function createTerraformProject() {
  // This would be handled by the Gemini Code Assist extension
  console.log('Terraform project structure:');
  console.log('- main.tf: Main Terraform configuration file');
  console.log('- variables.tf: Variable definitions');
  console.log('- outputs.tf: Output definitions');
  console.log('- terraform.tfvars: Variable values');
  console.log('- deploy.sh: Deployment script');
}

// Output
console.log('Terraform configuration generated for deploying n2d-standard-32 with 2x NVIDIA T4 GPUs');
console.log('Save these files to create a complete Terraform project:');
console.log('1. main.tf - Main configuration');
console.log('2. variables.tf - Variable definitions');
console.log('3. outputs.tf - Output definitions');
console.log('4. terraform.tfvars - Variable values');
console.log('5. deploy.sh - Deployment script');
console.log('');
console.log('Then execute with: terraform init && terraform apply');
