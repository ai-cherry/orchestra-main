name: AI Codebase Hygiene & Performance Monitoring

on:
  schedule:
    - cron: "0 2 * * 0"  # Weekly, Sunday at 2 AM UTC
  push:
    branches: [main, develop]
  pull_request:
    branches: [main, develop]
  workflow_dispatch:  # Allow manual triggering

jobs:
  hygiene-and-linting:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Needed for git blame/log analysis

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -r requirements/base.txt
          pip install black flake8 isort mypy

      - name: Run Black formatter check
        run: |
          echo "üé® Running Black formatter check..."
          black --check .
        continue-on-error: true

      - name: Run Flake8 linter
        run: |
          echo "üîç Running Flake8 linter..."
          flake8 . --config=.flake8
        continue-on-error: true

      - name: Run isort import check
        run: |
          echo "üì¶ Running isort import sorter check..."
          isort --check-only .
        continue-on-error: true

      - name: Run mypy type checker
        run: |
          echo "üî§ Running mypy type checker..."
          mypy . --config-file=mypy.ini
        continue-on-error: true

      - name: Check for hardcoded secrets
        run: |
          echo "üîê Checking for hardcoded secrets..."
          python scripts/scan_for_hardcoded_values.py

      - name: Run File Inventory Script
        id: inventory
        run: |
          echo "üìã Starting comprehensive codebase inventory..."
          chmod +x scripts/comprehensive_inventory.sh
          ./scripts/comprehensive_inventory.sh
          echo "Inventory generated: cleanup_inventory.json"
          
          # Create reports directory
          mkdir -p reports
          cp cleanup_inventory.json reports/cleanup_inventory_$(date +%Y%m%d).json

      - name: Analyze Inventory (Dry Run Cleanup Check)
        if: steps.inventory.outcome == 'success'
        run: |
          echo "üßπ Analyzing cleanup candidates..."
          python ./scripts/cleanup_engine.py cleanup_inventory.json --report-only > reports/cleanup_candidates_$(date +%Y%m%d).json
          
          # Generate summary
          cat > reports/cleanup_summary.txt << 'EOF'
          import json
          with open('reports/cleanup_candidates_$(date +%Y%m%d).json') as f:
              data = json.load(f)
          print(f'Total files analyzed: {data.get("total_files_analyzed", 0)}')
          print(f'Cleanup candidates: {data.get("cleanup_candidates", 0)}')
          EOF
          python reports/cleanup_summary.txt

      - name: Check Automation Scripts Health
        run: |
          echo "ü§ñ Checking automation scripts health..."
          if [ -f "scripts/automation_manager.py" ]; then
            python scripts/automation_manager.py health > reports/automation_health_$(date +%Y%m%d).json
          fi

      - name: Performance Analysis
        run: |
          echo "‚ö° Running performance checks..."
          # Check for functions without type hints
          echo "Functions without type hints:"
          grep -r "def " --include="*.py" . | grep -v "def.*->.*:" | head -20 || true
          
          # Check for large files
          echo -e "\nLarge Python files (>700KB):"
          find . -name "*.py" -size +700k -exec ls -lh {} \; || true
          
          # Check for complex functions (basic check)
          echo -e "\nPotentially complex functions (>50 lines):"
          cat > /tmp/check_complex.py << 'EOF'
          import ast
          import os
                  continue
              for file in files:
                  if file.endswith('.py'):
                      try:
                              tree = ast.parse(f.read())
                          for node in ast.walk(tree):
                              if isinstance(node, ast.FunctionDef):
                                  if hasattr(node, 'end_lineno') and hasattr(node, 'lineno'):
                                      if node.end_lineno - node.lineno > 50:
                      except: pass
          EOF
          python /tmp/check_complex.py | head -20 || true

      - name: Generate Code Quality Report
        run: |
          echo "üìä Generating code quality report..."
          DATE=$(date +%Y%m%d)
          cat > reports/code_quality_report_${DATE}.md << 'EOF'
          # Code Quality Report - $(date +%Y-%m-%d)
          
          ## Summary
          - Total Python files: $(find . -name "*.py" -not -path "./venv/*" -not -path "./.git/*" | wc -l)
          - Total lines of code: $(find . -name "*.py" -not -path "./venv/*" -not -path "./.git/*" -exec wc -l {} + | tail -1 | awk '{print $1}')
          
          ## Cleanup Analysis
          EOF
          
          # Add cleanup analysis
          if [ -f "reports/cleanup_candidates_${DATE}.json" ]; then
            cat >> reports/code_quality_report_${DATE}.md << 'EOF'
          $(cat > /tmp/analyze_cleanup.py << 'SCRIPT'
          import json
          try:
              with open('reports/cleanup_candidates_${DATE}.json') as f:
                  data = json.load(f)
              print(f'- Files analyzed: {data.get("total_files_analyzed", 0)}')
              print(f'- Cleanup candidates: {data.get("cleanup_candidates", 0)}')
              if 'candidates' in data and data['candidates']:
                  print('\n### Top cleanup candidates:')
                  for c in data['candidates'][:10]:
                      print(f"  - {c['path']}: {c['reason']}")
          except: print('- Cleanup analysis not available')
          SCRIPT
          python /tmp/analyze_cleanup.py)
          EOF
          fi
          
          # Add automation health
          cat >> reports/code_quality_report_${DATE}.md << 'EOF'
          
          ## Automation Health
          EOF
          
          if [ -f "reports/automation_health_${DATE}.json" ]; then
            cat >> reports/code_quality_report_${DATE}.md << 'EOF'
          $(cat > /tmp/analyze_automation.py << 'SCRIPT'
          import json
          try:
              with open('reports/automation_health_${DATE}.json') as f:
                  data = json.load(f)
              print(f'- Total scripts: {data.get("total_scripts", 0)}')
              print(f'- Healthy: {data.get("healthy", 0)}')
              print(f'- Failed: {data.get("failed", 0)}')
          except: print('- Automation health data not available')
          SCRIPT
          python /tmp/analyze_automation.py)
          EOF
          fi

      - name: Upload Reports Artifact
        uses: actions/upload-artifact@v4
        with:
          name: codebase-hygiene-reports-${{ github.run_id }}
          path: |
            reports/
            cleanup_actions.log
          retention-days: 30

      - name: Comment PR with Summary (if PR)
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            let summary = '## üßπ Codebase Hygiene Check\n\n';
            
            try {
              // Read cleanup candidates
              const candidatesFile = fs.readdirSync('reports').find(f => f.startsWith('cleanup_candidates_'));
              if (candidatesFile) {
                const data = JSON.parse(fs.readFileSync(`reports/${candidatesFile}`, 'utf8'));
                summary += `- **Files analyzed**: ${data.total_files_analyzed || 0}\n`;
                summary += `- **Cleanup candidates**: ${data.cleanup_candidates || 0}\n\n`;
                
                if (data.cleanup_candidates > 0) {
                  summary += '‚ö†Ô∏è **Action Required**: Review cleanup candidates in the artifacts.\n';
                }
              }
            } catch (e) {
              summary += '- Cleanup analysis not available\n';
            }
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: summary
            });

  security-scan:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Run Bandit Security Scan
        run: |
          pip install bandit
          mkdir -p reports
          bandit -r . -f json -o reports/bandit_report.json || true
          
      - name: Upload Security Report
        uses: actions/upload-artifact@v4
        with:
          name: security-report-${{ github.run_id }}
          path: reports/bandit_report.json
          retention-days: 30