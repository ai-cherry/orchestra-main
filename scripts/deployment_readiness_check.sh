#!/bin/bash
# Deployment Readiness Check - Shows what's needed for different environments

echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
echo "â•‘              DEPLOYMENT READINESS CHECK                          â•‘"
echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo

# Function to check if a key exists
check_key() {
    local key=$1
    local value="${!key}"
    if [ -n "$value" ] || grep -q "^$key=" .env 2>/dev/null; then
        echo "âœ…"
    else
        echo "âŒ"
    fi
}

echo "ğŸ  LOCAL DEVELOPMENT REQUIREMENTS"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "These are REQUIRED for local development:"
echo
echo "[$(check_key DATABASE_URL)] PostgreSQL Database"
echo "[$(check_key ANTHROPIC_API_KEY)] At least one AI API key (Anthropic/OpenAI/etc)"
echo
echo "Status: Your AI orchestration is FULLY FUNCTIONAL locally! âœ…"
echo

echo "â˜ï¸  PRODUCTION DEPLOYMENT REQUIREMENTS"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "These are ONLY needed when deploying to production:"
echo

echo "ğŸ”¹ Vultr Cloud Deployment:"
echo "[$(check_key VULTR_API_KEY)] VULTR_API_KEY - Deploy servers on Vultr"
echo "   â””â”€ Without this: Cannot deploy to Vultr cloud"
echo "   â””â”€ Alternative: Deploy manually or use different cloud"
echo

echo "ğŸ”¹ Infrastructure as Code (Optional):"
echo "[$(check_key PULUMI_CONFIG_PASSPHRASE)] PULUMI_CONFIG_PASSPHRASE - Encrypt Pulumi state"
echo "   â””â”€ Without this: Use unencrypted local state (fine for dev)"
echo "[$(check_key AWS_ACCESS_KEY_ID)] AWS_ACCESS_KEY_ID - Store Pulumi state in S3"
echo "[$(check_key AWS_SECRET_ACCESS_KEY)] AWS_SECRET_ACCESS_KEY - Store Pulumi state in S3"
echo "   â””â”€ Without these: Use local file state (perfectly fine)"
echo

echo "ğŸ”¹ Data Pipeline Integration (Optional):"
echo "[$(check_key AIRBYTE_API_KEY)] AIRBYTE_API_KEY - Connect to Airbyte"
echo "[$(check_key AIRBYTE_API_URL)] AIRBYTE_API_URL - Airbyte endpoint"
echo "[$(check_key AIRBYTE_WORKSPACE_ID)] AIRBYTE_WORKSPACE_ID - Airbyte workspace"
echo "   â””â”€ Without these: No automated data pipelines (not needed for AI orchestration)"
echo

echo
echo "ğŸ“Š SUMMARY"
echo "â•â•â•â•â•â•â•â•â•"

# Count what's configured
local_ready=true
if ! check_key DATABASE_URL >/dev/null || ! (check_key ANTHROPIC_API_KEY >/dev/null || check_key OPENAI_API_KEY >/dev/null); then
    local_ready=false
fi

if [ "$local_ready" = true ]; then
    echo "âœ… Local Development: READY"
    echo "   Your AI orchestration system is fully functional!"
else
    echo "âš ï¸  Local Development: Missing core requirements"
fi

if check_key VULTR_API_KEY >/dev/null; then
    echo "âœ… Cloud Deployment: READY (Vultr configured)"
else
    echo "ğŸ“Œ Cloud Deployment: Not configured (optional)"
fi

echo
echo "ğŸ’¡ WHAT YOU NEED TO DO:"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
if [ "$local_ready" = true ]; then
    echo "âœ… Nothing! Your system is ready for local use."
    echo
    echo "For production deployment (optional):"
    echo "1. Get a Vultr API key from https://my.vultr.com/settings/#settingsapi"
    echo "2. Run: export VULTR_API_KEY='your-key-here'"
    echo "3. Use Pulumi to deploy: cd infrastructure && pulumi up"
else
    echo "1. Ensure PostgreSQL is running"
    echo "2. Add at least one AI API key to .env"
    echo "3. Run: ./scripts/test_orchestrator_demo.py"
fi