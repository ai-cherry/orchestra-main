# Orchestra environment configuration example
# Copy this file to .env and fill in your actual keys

# Environment settings
# Options: development, test, staging, production
APP_ENV=development

# API Keys
# Required for OpenRouter LLM integration (legacy, consider using Portkey virtual keys instead)
OPENROUTER_API_KEY=your_openrouter_api_key_here

# Portkey Integration
# Required for Portkey integration
PORTKEY_API_KEY=your_portkey_api_key_here
PREFERRED_LLM_PROVIDER=portkey

# Portkey Virtual Keys Management
# Admin key for creating/managing virtual keys (only needed for key management)
MASTER_PORTKEY_ADMIN_KEY=your_portkey_admin_key_here

# Virtual keys for different providers (you'll get these after creating keys with the CLI tool)
PORTKEY_VIRTUAL_KEY_OPENAI=vk_openai_...
PORTKEY_VIRTUAL_KEY_ANTHROPIC=vk_anthropic_...
PORTKEY_VIRTUAL_KEY_MISTRAL=vk_mistral_...
PORTKEY_VIRTUAL_KEY_HUGGINGFACE=vk_huggingface_...
PORTKEY_VIRTUAL_KEY_COHERE=vk_cohere_...
PORTKEY_VIRTUAL_KEY_OPENROUTER=vk_openrouter_...
# Add more provider virtual keys as needed

# Portkey Gateway Configuration (for routing and fallbacks)
PORTKEY_CONFIG_ID=gw_config_...
PORTKEY_STRATEGY=fallback
PORTKEY_CACHE_ENABLED=true

# Site information (used for API request headers)
SITE_URL=http://localhost
SITE_TITLE=Orchestra-Main Development

# LLM Model Settings
# Multi-service strategy models (for Portkey+OpenRouter+Fallbacks)
DEFAULT_LLM_MODEL_PRIMARY=openai/gpt-4o          # Primary model via OpenRouter
DEFAULT_LLM_MODEL_FALLBACK_OPENAI=gpt-4o         # Fallback model for OpenAI (direct)
DEFAULT_LLM_MODEL_FALLBACK_ANTHROPIC=claude-3-5-sonnet-20240620  # Fallback model for Anthropic (direct)
DEFAULT_LLM_MODEL=openai/gpt-3.5-turbo           # Legacy setting (used if PRIMARY not set)

# LLM Request settings
LLM_REQUEST_TIMEOUT=30
LLM_MAX_RETRIES=3
LLM_RETRY_DELAY=1.0
LLM_RETRY_MAX_DELAY=60.0

# LLM Semantic Caching (reduces API calls for similar requests)
LLM_SEMANTIC_CACHE_ENABLED=true
LLM_SEMANTIC_CACHE_THRESHOLD=0.85
LLM_SEMANTIC_CACHE_TTL=3600

# Google Cloud Platform settings
# Required for Firestore storage, Redis, Vertex AI, etc.
# Project identification 
GCP_PROJECT_ID=your-gcp-project-id
GOOGLE_CLOUD_PROJECT=your-gcp-project-id  # Optional alias, for compatibility
GCP_LOCATION=us-west2  # Default region for GCP services

# Authentication (choose ONE method)
# Method 1: Provide the entire service account key JSON content (recommended for Codespaces/Cloud Run)
GCP_SA_KEY_JSON={"type":"service_account","project_id":"your-project-id","private_key_id":"..."}

# Method 2: Provide path to the service account JSON key file
GOOGLE_APPLICATION_CREDENTIALS=/path/to/your-key-file.json

# Method 3: Use Application Default Credentials (ADC)
# No configuration needed if running in GCP or after running 'gcloud auth application-default login'

# Redis settings (for caching)
# Required for production environments
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=
# Cache TTL in seconds (default: 3600 = 1 hour)
CACHE_TTL=3600
