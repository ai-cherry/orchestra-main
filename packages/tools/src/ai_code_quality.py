"""
AI Code Quality Checks for the Orchestra System.

This module provides a set of tools to detect and flag potential issues in AI-related code,
including hallucinated code patterns, prompt injection vectors, context window management
in RAG implementations, and model version drift in AI service integrations.
"""

import re
import ast
import os
from typing import List, Dict, Tuple, Optional
from pathlib import Path


class HallucinationDetector:
    """
    Detects potential hallucinated code patterns that may originate from AI-generated sources.
    """

    def __init__(self):
        self.patterns = [
            (
                r"#.*(AI-generated|generated by AI|auto-generated by AI)",
                "AI-generated comment detected",
            ),
            (
                r"def\s+\w+\s*\(\s*\)\s*:\s*\n\s*pass",
                "Empty function definition, possible placeholder",
            ),
            (
                r"for\s+\w+\s+in\s+range\(\d+\)\s*:\s*\n\s*pass",
                "Empty loop, possible placeholder",
            ),
        ]

    def check_file(self, file_path: str) -> List[Tuple[int, str, str]]:
        """
        Check a file for hallucinated code patterns.

        Args:
            file_path: Path to the file to check.

        Returns:
            List of tuples containing (line_number, line_content, issue_description).
        """
        issues = []
        try:
            with open(file_path, "r", encoding="utf-8") as file:
                lines = file.readlines()
                for i, line in enumerate(lines, 1):
                    for pattern, description in self.patterns:
                        if re.search(pattern, line):
                            issues.append((i, line.strip(), description))
        except Exception as e:
            print(f"Error reading file {file_path}: {e}")
        return issues


class PromptInjectionChecker:
    """
    Identifies potential prompt injection vectors in LLM interactions.
    """

    def __init__(self):
        self.vulnerable_patterns = [
            (
                r"format\s*\(\s*[^)]*user_input[^)]*\)",
                "Direct string formatting with user input",
            ),
            (r"\+\s*user_input\s*\+", "String concatenation with user input"),
            (
                r"prompt\s*=.*\{\}.*format\s*\(",
                "Unescaped user input in prompt formatting",
            ),
        ]

    def check_file(self, file_path: str) -> List[Tuple[int, str, str]]:
        """
        Check a file for potential prompt injection vulnerabilities.

        Args:
            file_path: Path to the file to check.

        Returns:
            List of tuples containing (line_number, line_content, issue_description).
        """
        issues = []
        try:
            with open(file_path, "r", encoding="utf-8") as file:
                lines = file.readlines()
                for i, line in enumerate(lines, 1):
                    for pattern, description in self.vulnerable_patterns:
                        if re.search(pattern, line):
                            issues.append((i, line.strip(), description))
        except Exception as e:
            print(f"Error reading file {file_path}: {e}")
        return issues


class RAGContextValidator:
    """
    Validates proper context window management in Retrieval-Augmented Generation (RAG) implementations.
    """

    def __init__(self):
        self.context_patterns = [
            (
                r"context\s*=.*list|dict|str",
                "Context variable assignment without token limit check",
            ),
            (
                r"messages\s*=.*append\s*\(\s*context",
                "Context added to messages without truncation",
            ),
        ]

    def check_file(self, file_path: str) -> List[Tuple[int, str, str]]:
        """
        Check a file for proper context window management in RAG implementations.

        Args:
            file_path: Path to the file to check.

        Returns:
            List of tuples containing (line_number, line_content, issue_description).
        """
        issues = []
        try:
            with open(file_path, "r", encoding="utf-8") as file:
                lines = file.readlines()
                for i, line in enumerate(lines, 1):
                    for pattern, description in self.context_patterns:
                        if re.search(pattern, line):
                            issues.append((i, line.strip(), description))
        except Exception as e:
            print(f"Error reading file {file_path}: {e}")
        return issues


class ModelVersionMonitor:
    """
    Checks for potential model version drift in AI service integrations.
    """

    def __init__(self):
        # List of known outdated models or versions for flagging
        self.outdated_models = {
            "gpt-3.5-turbo": "Consider updating to gpt-4 or gpt-4o",
            "claude-2": "Consider updating to claude-3 or later",
            "text-davinci-003": "Deprecated model, update to gpt-4 or similar",
        }

    def check_file(self, file_path: str) -> List[Tuple[int, str, str]]:
        """
        Check a file for outdated model versions or potential version drift.

        Args:
            file_path: Path to the file to check.

        Returns:
            List of tuples containing (line_number, line_content, issue_description).
        """
        issues = []
        try:
            with open(file_path, "r", encoding="utf-8") as file:
                lines = file.readlines()
                for i, line in enumerate(lines, 1):
                    for model, suggestion in self.outdated_models.items():
                        if model in line:
                            issues.append(
                                (
                                    i,
                                    line.strip(),
                                    f"Outdated model '{model}' detected. {suggestion}",
                                )
                            )
        except Exception as e:
            print(f"Error reading file {file_path}: {e}")
        return issues


def run_ai_code_quality_checks(directory: str) -> Dict[str, List[Tuple[int, str, str]]]:
    """
    Run all AI code quality checks on Python files in the specified directory.

    Args:
        directory: Root directory to start the search for Python files.

    Returns:
        Dictionary mapping file paths to lists of issues found.
    """
    detectors = [
        HallucinationDetector(),
        PromptInjectionChecker(),
        RAGContextValidator(),
        ModelVersionMonitor(),
    ]
    results = {}

    for root, _, files in os.walk(directory):
        for file in files:
            if file.endswith(".py"):
                file_path = os.path.join(root, file)
                file_issues = []
                for detector in detectors:
                    file_issues.extend(detector.check_file(file_path))
                if file_issues:
                    results[file_path] = file_issues

    return results


if __name__ == "__main__":
    import sys

    directory_to_check = sys.argv[1] if len(sys.argv) > 1 else "."
    issues = run_ai_code_quality_checks(directory_to_check)
    if issues:
        print("AI Code Quality Issues Found:")
        for file_path, file_issues in issues.items():
            print(f"\nFile: {file_path}")
            for line_num, line_content, issue_desc in file_issues:
                print(f"  Line {line_num}: {issue_desc}")
                print(f"    {line_content}")
    else:
        print("No AI code quality issues found.")
