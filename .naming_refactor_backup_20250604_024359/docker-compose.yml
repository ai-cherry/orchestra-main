version: '3.8'

services:
  api:
    build: .
    ports:
      - "8000:8001"
    environment:
      # Database Configuration (Docker service names)
      DATABASE_URL: postgresql://postgres:postgres@postgres:5432/cherry_ai
      POSTGRES_URL: postgresql://postgres:postgres@postgres:5432/cherry_ai
      POSTGRES_HOST: postgres
      POSTGRES_PORT: "5432"
      POSTGRES_DB: cherry_ai
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-postgres}

      # Redis Configuration (Docker service name)
      REDIS_URL: redis://redis:6379

      # Weaviate Configuration (Docker service name)
      WEAVIATE_URL: http://weaviate:8080
      WEAVIATE_HOST: weaviate
      WEAVIATE_PORT: "8080"
      WEAVIATE_API_KEY: ${WEAVIATE_API_KEY:-}

      # API Configuration
      API_HOST: 0.0.0.0
      API_PORT: "8001"
      DEBUG: "false"
      ENVIRONMENT: development

      # API Keys (use environment variables if set)
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY:-}
      PORTKEY_API_KEY: ${PORTKEY_API_KEY:-}
      VULTR_API_KEY: ${VULTR_API_KEY:-}

      # MCP Server Configuration
      CHERRY_AI_CONDUCTOR_PORT: "8002"
      MCP_MEMORY_PORT: "8003"
      MCP_TOOLS_PORT: "8006"
      MCP_WEAVIATE_DIRECT_PORT: "8001"
      MCP_DEPLOYMENT_PORT: "8005"
    depends_on:
      - postgres
      - redis
      - weaviate
    restart: always
    volumes:
      - ./logs:/app/logs

  admin-ui:
    build: ./admin-ui
    ports:
      - "3000:3000"
    environment:
      - VITE_API_URL=https://cherry-ai.me/api
    restart: always

  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: cherry_ai
      POSTGRES_USER: cherry_ai
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-secure_password_2025}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: always
    healthcheck:
      test: [ "CMD", "pg_isready", "-U", "cherry_ai" ]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    command: redis-server --maxmemory 2gb --maxmemory-policy allkeys-lru
    restart: always
    # Redis is used for general-purpose and semantic caching. Configure for performance and resource limits.
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      interval: 10s
      timeout: 5s
      retries: 5

  weaviate:
    image: semitechnologies/weaviate:latest
    ports:
      - "8080:8080"
    environment:
      PERSISTENCE_DATA_PATH: /var/lib/weaviate
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'false'
      DEFAULT_VECTORIZER_MODULE: 'text2vec-openai'
      ENABLE_MODULES: 'text2vec-openai'
    volumes:
      - weaviate_data:/var/lib/weaviate
    restart: always
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8080/v1/.well-known/ready" ]
      interval: 15s
      timeout: 10s
      retries: 8

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - /etc/letsencrypt:/etc/letsencrypt:ro
    depends_on:
      - api
      - admin-ui
    restart: always

volumes:
  postgres_data:
  weaviate_data:

    # Docker Compose is the preferred way to run the full stack locally for development and testing.
