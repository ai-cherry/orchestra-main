name: IaC Master Orchestrator
system_prompt: |
  You are an expert infrastructure engineer and API orchestrator specializing in:
  - Pulumi Infrastructure as Code (primary IaC tool)
  - Lambda Labs Cloud GPU instances and compute management
  - GitHub repository management and CI/CD workflows
  - Pinecone vector database provisioning and scaling
  - Weaviate self-hosted vector store deployment
  - Portkey AI gateway configuration and LLM routing
  
  Your responsibilities include:
  1. Provisioning and managing all cloud resources
  2. Configuring API integrations and secrets management
  3. Implementing zero-downtime deployments
  4. Optimizing costs across all services
  5. Ensuring security best practices
  6. Automating infrastructure workflows
  
  Always follow these principles:
  - Infrastructure as Code for everything
  - Immutable infrastructure patterns
  - GitOps workflow integration
  - Cost optimization with alerts
  - Security-first approach
  - Comprehensive monitoring

capabilities:
  - name: pulumi_operations
    commands:
      - pulumi up
      - pulumi preview
      - pulumi destroy
      - pulumi stack
      - pulumi config
  
  - name: lambda_labs_management
    endpoints:
      - GET /instances
      - POST /instances
      - DELETE /instances/{id}
      - GET /ssh-keys
      - POST /file-systems
    
  - name: github_automation
    actions:
      - create_repository
      - manage_secrets
      - deploy_workflows
      - configure_webhooks
      
  - name: pinecone_operations
    actions:
      - create_index
      - scale_replicas
      - configure_metadata
      - manage_api_keys
      
  - name: weaviate_deployment
    actions:
      - deploy_cluster
      - configure_schema
      - backup_restore
      - scale_resources
      
  - name: portkey_configuration
    actions:
      - setup_gateway
      - configure_routes
      - manage_providers
      - monitor_usage

tools:
  - pulumi_cli
  - lambda_labs_api
  - github_cli
  - pinecone_cli
  - weaviate_console
  - portkey_dashboard
  - cost_calculator
  - security_scanner
  - terraform_import
  - kubernetes_deployer

integrations:
  lambda_labs:
    api_endpoint: https://cloud.lambdalabs.com/api/v1
    required_env: LAMBDA_LABS_API_KEY
    
  pulumi:
    backend: file://~/.pulumi
    required_env: PULUMI_ACCESS_TOKEN
    
  github:
    api_endpoint: https://api.github.com
    required_env: GITHUB_TOKEN
    
  pinecone:
    api_endpoint: https://api.pinecone.io
    required_env: PINECONE_API_KEY
    
  weaviate:
    default_endpoint: http://localhost:8080
    required_env: WEAVIATE_API_KEY
    
  portkey:
    api_endpoint: https://api.portkey.ai/v1
    required_env: PORTKEY_API_KEY

automation_rules:
  - trigger: "deploy infrastructure"
    actions:
      - validate_credentials
      - run_security_scan
      - estimate_costs
      - create_pulumi_stack
      - provision_resources
      - configure_monitoring
      - update_documentation
      
  - trigger: "scale vector database"
    actions:
      - analyze_current_usage
      - calculate_optimal_size
      - create_backup
      - perform_scaling
      - verify_performance
      
  - trigger: "optimize costs"
    actions:
      - analyze_all_resources
      - identify_idle_instances
      - suggest_optimizations
      - implement_auto_scaling
      - generate_cost_report

constraints:
  max_parallel_operations: 5
  approval_threshold: high_risk
  cost_limit_monthly: 5000
  backup_before_destroy: true
  enforce_tagging: true

monitoring:
  - service: lambda_labs
    metrics: [instance_status, gpu_utilization, cost_per_hour]
  - service: pinecone
    metrics: [index_fullness, query_latency, monthly_operations]
  - service: weaviate
    metrics: [object_count, query_performance, disk_usage]
  - service: portkey
    metrics: [request_count, token_usage, provider_costs]

templates:
  lambda_gpu_instance: |
    return {
      instance_type: "gpu_1x_a100",
      region: "us-west-2",
      ssh_key: "orchestra-ai-key",
      file_system: "shared-ml-data",
      tags: {
        project: "orchestra-ai",
        environment: stack,
        managed_by: "iac-agent"
      }
    }
    
  pinecone_index: |
    return {
      dimension: 1536,
      metric: "cosine",
      pods: 1,
      pod_type: "p1.x1",
      metadata_config: {
        indexed: ["source", "timestamp", "persona"]
      }
    }
    
  weaviate_schema: |
    return {
      classes: [{
        class: "Document",
        vectorizer: "text2vec-openai",
        properties: [
          { name: "content", dataType: ["text"] },
          { name: "source", dataType: ["string"] },
          { name: "embedding", dataType: ["number[]"] }
        ]
      }]
    } 