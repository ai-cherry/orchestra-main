{
  "rules": [
    {
      "tags": ["cursor", "ai-assistant"],
      "message": "You are working on the Cherry AI Orchestrator project - a comprehensive AI-powered infrastructure management system.\n\n**Production Infrastructure:**\n- Production server: 45.32.69.157 (16 vCPUs, 64GB RAM)\n- Database server: 45.77.87.106 (PostgreSQL, Redis)\n- Staging server: 207.246.108.201\n- Load balancer and Kubernetes cluster\n\n**Tech Stack:**\n- Frontend: HTML5, CSS3, JavaScript (Vanilla)\n- Backend: Python 3.11, Flask, FastAPI\n- Databases: PostgreSQL, Redis, Weaviate, Pinecone\n- Infrastructure: Lambda, Pulumi IaC\n- CI/CD: GitHub Actions\n- AI Services: Anthropic Claude, Google Gemini\n\n**Key Components:**\n- Admin interface with three AI personas (for end users, not coding)\n- MCP servers for development tool integration\n- Infrastructure automation and monitoring\n- Vector databases for semantic search\n- Real-time deployment pipeline\n\n**Development Tools:**\n- Cursor AI with Max Mode for large context analysis\n-  Code with custom modes (cherry-dev, infra, database)\n- Three optimized MCP servers (codebase, infrastructure, database)\n\n**Coding Standards:**\n- Use type hints in Python\n- Follow PEP 8 style guide\n- Write comprehensive docstrings\n- Include error handling and logging\n- Use environment variables for secrets\n- Write tests for all new functionality\n\n**Security:**\n- Never hardcode API keys or secrets\n- Use GitHub organization secrets\n- Implement proper authentication\n- Follow OWASP security guidelines\n\nWhen suggesting code changes, consider the production environment and ensure compatibility with the existing infrastructure."
    },
    {
      "tags": ["python"],
      "message": "For Python code in the Cherry AI project:\n\n**Imports:**\n- Use absolute imports\n- Group imports: standard library, third-party, local\n- Import only what you need\n\n**Error Handling:**\n- Use specific exception types\n- Log errors with context\n- Implement graceful degradation\n\n**Async Code:**\n- Use async/await for I/O operations\n- Handle asyncio exceptions properly\n- Use connection pooling for databases\n\n**Environment Variables:**\n- Load from .env files using python-dotenv\n- Validate required environment variables\n- Provide sensible defaults where appropriate\n\n**Example pattern:**\n```python\nimport os\nfrom typing import Optional\nfrom dotenv import load_dotenv\nimport logging\n\nload_dotenv()\nlogger = logging.getLogger(__name__)\n\nclass ServiceManager:\n    def __init__(self):\n        self.api_key = os.getenv('API_KEY')\n        if not self.api_key:\n            raise ValueError('API_KEY environment variable required')\n    \n    async def process_request(self, data: dict) -> Optional[dict]:\n        try:\n            # Implementation here\n            return result\n        except Exception as e:\n            logger.error(f'Error processing request: {e}')\n            raise\n```"
    },
    {
      "tags": ["javascript", "frontend"],
      "message": "For JavaScript/Frontend code in the Cherry AI project:\n\n**Modern JavaScript:**\n- Use ES6+ features (const/let, arrow functions, async/await)\n- Implement proper error handling\n- Use fetch API for HTTP requests\n- Follow responsive design principles\n\n**UI/UX Guidelines:**\n- Mobile-first responsive design\n- Accessible components (ARIA labels)\n- Loading states and error messages\n- Consistent color scheme and typography\n\n**API Integration:**\n- Handle loading states\n- Implement retry logic\n- Show user-friendly error messages\n- Use proper HTTP status codes\n\n**Example pattern:**\n```javascript\nclass APIClient {\n  constructor(baseURL) {\n    this.baseURL = baseURL;\n  }\n  \n  async request(endpoint, options = {}) {\n    try {\n      const response = await fetch(`${this.baseURL}${endpoint}`, {\n        headers: {\n          'Content-Type': 'application/json',\n          ...options.headers\n        },\n        ...options\n      });\n      \n      if (!response.ok) {\n        throw new Error(`HTTP ${response.status}: ${response.statusText}`);\n      }\n      \n      return await response.json();\n    } catch (error) {\n      console.error('API request failed:', error);\n      throw error;\n    }\n  }\n}\n```"
    },
    {
      "tags": ["infrastructure", "devops"],
    },
    {
      "tags": ["database"],
      "message": "For Database operations in the Cherry AI project:\n\n**PostgreSQL Best Practices:**\n- Use connection pooling\n- Implement proper indexing\n- Use prepared statements\n- Handle transactions properly\n- Monitor query performance\n\n**Redis Caching:**\n- Set appropriate TTL values\n- Use Redis for session management\n- Implement cache invalidation\n- Monitor memory usage\n\n**Vector Databases:**\n- Optimize embedding strategies\n- Use appropriate distance metrics\n- Implement proper chunking\n- Monitor performance and costs\n\n**Example database pattern:**\n```python\nimport asyncpg\nimport redis\nfrom typing import Optional\n\nclass DatabaseManager:\n    def __init__(self):\n        self.pg_pool = None\n        self.redis_client = redis.Redis(host='45.77.87.106')\n    \n    async def init_postgres(self):\n        self.pg_pool = await asyncpg.create_pool(\n            host='45.77.87.106',\n            database='cherry_ai',\n            user='postgres',\n            password=os.getenv('POSTGRES_PASSWORD'),\n            min_size=5,\n            max_size=20\n        )\n    \n    async def execute_query(self, query: str, *args) -> Optional[list]:\n        async with self.pg_pool.acquire() as conn:\n            return await conn.fetch(query, *args)\n```"
    }
  ],
  "include": ["**/*"],
  "exclude": [
    "node_modules/**",
    ".git/**",
    "__pycache__/**",
    "*.pyc",
    ".env*",
    "*.log",
    ".DS_Store",
    "venv/**",
    ".migration_backups/**"
  ]
}

